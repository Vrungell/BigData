{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Задачи:\\n- вывести топ 20 понравившихся, комментируемых, репостнутых постов по количеству (для обоих датасетов с постами)\\n- вывести топ 20 пользователей по сделанным лайкам и репостам (для репостов используйте \"copy_history\", из датасета постов подписчиков)\\n- получить репосты исходных постов группы itmo (posts.json) из постов пользователей (результат должен быть похож на (group_post_id, Array (user_post_ids)) ) \\n- найти смайлики в постах и комментариях к постам (негативные, позитивные, нейтральные) (можете использовать внешние библиотеки или предопределенные списки смайликов) (используйте функцию spark udf и broadcast для смайликов\\n- Найти друзей. Идея, если пользователи лайкают друг друга, то они друзья.  (*бонус)\\n- Найти поклонников. Идея, если пользователь лайкает другого, и это не взаимно, то первый поклонник. \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Задачи:\n",
    "- вывести топ 20 понравившихся, комментируемых, репостнутых постов по количеству (для обоих датасетов с постами)\n",
    "- вывести топ 20 пользователей по сделанным лайкам и репостам (для репостов используйте \"copy_history\", из датасета постов подписчиков)\n",
    "- получить репосты исходных постов группы itmo (posts.json) из постов пользователей (результат должен быть похож на (group_post_id, Array (user_post_ids)) ) \n",
    "- найти смайлики в постах и комментариях к постам (негативные, позитивные, нейтральные) (можете использовать внешние библиотеки или предопределенные списки смайликов) (используйте функцию spark udf и broadcast для смайликов\n",
    "- Найти друзей. Идея, если пользователи лайкают друг друга, то они друзья.  (*бонус)\n",
    "- Найти поклонников. Идея, если пользователь лайкает другого, и это не взаимно, то первый поклонник. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "import emojis\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['JAVA_HOME'] = '/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home'\n",
    "#print(os.environ.get('JAVA_HOME'))\n",
    "\n",
    "conf = SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data_dir = ''\n",
    "followers = os.path.join(big_data_dir, 'followers.parquet/followers.parquet')\n",
    "#concated with cat\n",
    "followers_posts = os.path.join(big_data_dir, 'followers_posts_api_final.json/followers_posts_api_final_common.json')\n",
    "followers_posts_likes = os.path.join(big_data_dir, 'followers_posts_likes.parquet/followers_posts_likes_1.parquet')\n",
    "posts = os.path.join(big_data_dir, 'posts_api.json/posts_api.json')\n",
    "posts_likes = os.path.join(big_data_dir, 'posts_likes.parquet/posts_likes.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, isnan, when, trim, sort_array, explode, collect_list\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, ArrayType, LongType\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = sqlContext.read.json(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_posts_df = sqlContext.read.json(followers_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attachments',\n",
       " 'comments',\n",
       " 'copy_history',\n",
       " 'copyright',\n",
       " 'date',\n",
       " 'final_post',\n",
       " 'from_id',\n",
       " 'geo',\n",
       " 'id',\n",
       " 'is_pinned',\n",
       " 'key',\n",
       " 'likes',\n",
       " 'owner_id',\n",
       " 'post_source',\n",
       " 'post_type',\n",
       " 'reposts',\n",
       " 'signer_id',\n",
       " 'text',\n",
       " 'unavailable',\n",
       " 'views']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "followers_posts_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_posts(posts_df, prefix):\n",
    "    posts_df = posts_df.na.drop(subset=[\"date\"])\n",
    "\n",
    "    for column, file_postfix in [('like', 'liked'), ('repost', 'reposted'), ('comment', 'commented')]:\n",
    "        answer = posts_df.orderBy(posts_df[column + 's'].desc(), asc=False).limit(20).toPandas()\n",
    "        answer_json = answer.to_json()\n",
    "        with open('{}_top_{}.json'.format(prefix, file_postfix), 'w') as f:\n",
    "            f.write(answer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_posts(posts_df, 'task1_posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_posts(followers_posts_df, 'task1_followers_posts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_likes_df = spark.read.load(posts_likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_count = posts_likes_df.groupby('likerId').count()\n",
    "result = likes_count.orderBy(col('count').desc(), asc=False).limit(20)\n",
    "result_json = result.toPandas().to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task2_top_followers_likes.json', 'w') as f:\n",
    "    f.write(result_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history = followers_posts_df.withColumn('copy_history', explode('copy_history'))\n",
    "result = df_history.filter(df_history.copy_history.owner_id == '-94').groupby('owner_id').count().sort(\n",
    "    'count', ascending=False).limit(20)\n",
    "result_json = result.toPandas().to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task2_top_followers_reposts.json', 'w') as f:\n",
    "    f.write(result_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_df = spark.read.load(followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "| owner_id|count|\n",
      "+---------+-----+\n",
      "|  2547211|40204|\n",
      "|357231922|26715|\n",
      "|168543860|18853|\n",
      "| 50348231|11906|\n",
      "| 25646344|11122|\n",
      "|     null| 9858|\n",
      "|176861294| 9033|\n",
      "|141687240| 8808|\n",
      "|445159771| 8704|\n",
      "|143207077| 8471|\n",
      "|194073434| 8146|\n",
      "|    29840| 7293|\n",
      "|524656784| 7263|\n",
      "|459339006| 6814|\n",
      "|514384760| 6578|\n",
      "|483715951| 6140|\n",
      "|412181460| 5813|\n",
      "|461319529| 5724|\n",
      "|451211328| 5651|\n",
      "|426396104| 5545|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "followers_posts_df.groupby('owner_id').count().orderBy(col('count').desc()).limit(20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = df_history.filter(df_history.copy_history.owner_id == '-94')\n",
    "df_select = df_filter.select(df_filter.copy_history.id.alias(\"group_post_id\"), df_filter.id.alias(\"user_post_id\"))\n",
    "final = df_select.sort('copy_history.id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = final.groupby(\"group_post_id\").agg(collect_list(\"user_post_id\")).sort('group_post_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_json = result.toPandas().to_json()\n",
    "with open('task3_followers_reposts.json', 'w') as f:\n",
    "    f.write(result_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = spark.read.json('posts_api.json/posts_api.json')\n",
    "posts_df.createOrReplaceTempView(\"posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.extract_emoji(text)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_emoji(text):\n",
    "    return(emojis.get(text))\n",
    "spark.udf.register(\"extract_emoji\", extract_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.readwriter.DataFrameWriter at 0x119922320>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis_df = spark.sql(\"SELECT key, extract_emoji(text) as emoji FROM posts WHERE text is not null\")\n",
    "emojis_df.select('key', 'emoji').sort(desc(\"emoji\")).coalesce(1).write.format(\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = emojis_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_json = result.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task4_post_emojis.json', 'w') as f:\n",
    "    f.write(result_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_posts_likes_1 = \\\n",
    "    spark.read.load(\"followers_posts_likes.parquet/followers_posts_likes_1.parquet\")\n",
    "followers_posts_likes_2 = \\\n",
    "    spark.read.load(\"followers_posts_likes.parquet/followers_posts_likes_2.parquet\")\n",
    "followers_posts_likes_3 = \\\n",
    "    spark.read.load(\"followers_posts_likes.parquet/followers_posts_likes_3.parquet\")\n",
    "followers_posts_likes_4 = \\\n",
    "    spark.read.load(\"followers_posts_likes.parquet/followers_posts_likes_4.parquet\")\n",
    "followers_posts_likes_5 = \\\n",
    "    spark.read.load(\"followers_posts_likes.parquet/followers_posts_likes_5.parquet\")\n",
    "followers_posts_likes_6 = \\\n",
    "    spark.read.load(\"followers_posts_likes.parquet/followers_posts_likes_6.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_followers_posts_likes = functools.reduce(pyspark.sql.DataFrame.unionAll, \n",
    "                                              [followers_posts_likes_1, \n",
    "                                               followers_posts_likes_2, \n",
    "                                               followers_posts_likes_3, \n",
    "                                               followers_posts_likes_4, \n",
    "                                               followers_posts_likes_5, \n",
    "                                               followers_posts_likes_6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_followers_posts_likes = data_followers_posts_likes.select(pyspark.sql.functions.col('ownerId'), \n",
    "                                 pyspark.sql.functions.col('likerId')).\\\n",
    "    where(pyspark.sql.functions.col('ownerId') != pyspark.sql.functions.col('likerId')).distinct()\n",
    "\n",
    "friends = data_followers_posts_likes.alias('t1').\\\n",
    "    join(data_followers_posts_likes.alias('t2'), \n",
    "         (pyspark.sql.functions.col('t1.ownerId') == pyspark.sql.functions.col('t2.likerId')) &\n",
    "         (pyspark.sql.functions.col('t1.likerId') == pyspark.sql.functions.col('t2.ownerId'))).\\\n",
    "    select(pyspark.sql.functions.col('t1.ownerId').alias(\"id_user\"), \n",
    "           pyspark.sql.functions.col('t2.ownerId').alias(\"id_friend\")).\\\n",
    "    sort(\"id_friend\").groupby(\"id_user\").agg(pyspark.sql.functions.collect_list(\"id_friend\")).sort(\"id_user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task5_users_friends.json', 'w') as file:\n",
    "    file.write(friends.toPandas().to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fans = data_followers_posts_likes.alias('t1').\\\n",
    "    join(data_followers_posts_likes.alias('t2'), \n",
    "         (pyspark.sql.functions.col('t1.ownerId') == pyspark.sql.functions.col('t2.likerId')) &\n",
    "         (pyspark.sql.functions.col('t1.likerId') == pyspark.sql.functions.col('t2.ownerId')), \n",
    "        \"left_outer\").where(pyspark.sql.functions.col('t2.likerId').isNull()).\\\n",
    "    select(pyspark.sql.functions.col('t1.ownerId').alias(\"id_user\"), \n",
    "           pyspark.sql.functions.col('t1.likerId').alias(\"id_fan\")).\\\n",
    "    sort(\"id_fan\").groupby(\"id_user\").agg(pyspark.sql.functions.collect_list(\"id_fan\")).sort(\"id_user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('task6_users_fans.json', 'w') as file:\n",
    "    file.write(fans.toPandas().to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
